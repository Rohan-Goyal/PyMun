#+LATEX_HEADER: \usepackage[margin=0.8in]{geometry}
#+LATEX_HEADER: \raggedright
#+OPTIONS: toc:nil
* Criterion A
** Defining the Problem
My client is the supervisor of the school's MUN (Model United Nations) club. With their advice and supervision, I intend to develop a software solution which makes preparation for MUN easier for participating students (See appendix A-1 for discussion).

Presently, students preparing for MUN conferences face a variety of inconveniences when managing documents for various conferences. Without a tedious method of manually filing documents, links, resources, etc. it is easy to lose track of which documents correspond to which committee/agenda. It is also easy to lose track of resources and research - since research is often a mix of PDF files and links, searching for information across sources is hardly straightforward. Being able to index links and PDFs like this would make it a lot easier to write papers without getting lost in thousands of tabs.

I intend to create a system which, based on some user configuration, is automatically able to track and manage information in a way optimised for MUN participants. This includes being able to parse (and ideally process) semantic units such clauses, subclauses, paragraphs, conclusions, etc. Based on these, it will provide functions to search and sort documents. This system will classify documents based on their purpose/type (such as a script for a speech, a position paper, notes, etc.), and based on the committee and agenda they relate to, allowing students to more easily focus on one specific agenda/conference at a time.

*Word Count:240*
** COMMENT Crud
python application (with a minimal web GUI, and also a CLI so that I can actually use it) which, based on some simple initial configurations, is able to automatically create and analyse metadata for certain files, sort them into folders (including using links to show them in multiple folders). The solution will interface with the user's Google Drive using the PyDrive library/API, and manage documents that way.
As a member of the MUN club myself, I've faced these problems and in my experience they aren't exactly
- Managing documents which have different kinds, different committees, and different agendas.
- Dealing with structural requirements, formatting, etc.
NOTE: This would be perfect with emacs yasnippet+swoop+org, but NO. Apparently most of the world is too dumb to use an editor from the 60s written in LISP.
(I personally use linux, and can run python scripts without all that bother. But alas, other people use things not designed to be scripted and so I must use Drive APIs and PyInstaller).

** Solution and Rationale
My decision is to create a Python application with a minimal web GUI that manages the user's Google Drive files. Based on the user's configuration, it will run in the background and "watch" their Google drive, making the requisite changes. Something like this requires the ability to auto-start and run in the background on the user's machine, and so it has to use a native program rather than a web app or electron monstrosity.

Students have different workflows for managing documents, so the program must have a configuration UI for users, ideally one they're familiar with. Thus, the configuration UI will be based on a webform.
It will be necessary to use a language that compiles for all systems, since the target audience uses a mixture of Linux, MacOS and Windows devices (See appendix A-2).
The aim of this program is to automate file management for users. Thus, it needs to run in the background since forcing users to run it manually defeats the purpose.

I chose Python because it has a lot of simple libraries and APIs that can interface with google services. Specifically, google provides a set of APIs for dealing with docs, and third parties also provide more convenient wrappers such as PyDrive. Since much of the data will deal with semantic markup and document metadata, it will be represented internally using XML or JSON flat files. Python has excellent support for both of those, including converting them to and from native data structures.
# Furthermore, I have worked with python on previous projects in the past and so using something which I'm familiar with should save on development time and minimise errors.
*Word Count: 249*
** Success Criteria
*** COMMENT Crud
- Able to use links/references to place files in multiple folders based on metadata
- Has internal representation of folder hierarchies, files as objects, etc. (more design principle than criterion)
- Process documents, and interpret them as data structures (whether through markup language or trees) which enable better parsing and formatting of documents
- Has ability to handle ambiguity or poorly-formatted documents.
- Presumably does this through parsing ambiguous sections as something like annotations, and parsing the rest.
- Extracted links should automatically include title, metadata
- GDrive GUI option to archive a particular conference folder: Adds the "archive" tag/metadata to all assoc'd files
- [IDEA: Check browser tabs to see if file is open before edits. Use brotab]

*** General
1. Able to parse a Google docs document and add custom metadata tags.
2. Uses OAuth to access google drive, and stores client secrets securely.
3. Tags/metadata includes the document type (position paper, research, notes, clause/resolution drafts), committee, country, agenda.
4. Auto-formats clauses, managing indentation, lists, sublists, etc.
5. Configured using an HTML GUI (run offline/locally) which could be operated by a child of five
6. Able to recognise/classify research resources, including recognising links within documents
7. Integrates with existing document management systems (Zotero, Onedrive, Google Drive, etc.)
8. Program should run in the background periodically
*** Functionality
9. [@9] Attach custom tags to documents
10. Put links in folders accordingly
11. For clause/resolution docs, auto-format the commas, semi-colons, sublists, etc.
12. Replace naked links (when it's just http://, no fancy link text) in documents with a markdown-style syntax that includes the link's title and source

*** Configurability
13. [@13] Users define how frequently they want the program to run
14. Users can decide whether or not the program should auto-format documents
15. User can tell the program to look in a specific folder or sub-folder in their google drive, using Unix path syntax (such as "/Documents/MUN")
16. Users must be able to easily re-authorise and de-authorise the program (for privacy/security reasons)
17. Users should be able to specify custom rules, for classifying documents, based on the following criteria:
    - Contains <phrase>
    - Name=<phrase>
  # - Age=<number of days> (Age will be computed) based on the files last-modified date and the current date. All calculations will be done in *.

* Criterion B
** COMMENT Record of Tasks
See excel
** Structure Diagram: Overview of program working
#+DOWNLOADED: file:///home/rohan/Downloads/code2flow_VnMcbg.svg @ 2021-02-02 20:38:03
[[file:Criterion_B/2021-02-02_20-38-03_code2flow_VnMcbg.svg]]
*** COMMENT Rough drafting
A user workflow basically looks like:
- Configure the program
- Launch the script (or have it launch automatically on startup)
- Wait
- Open up google drive
- Use the features provided () to navigate through google drive more effectively.

Program internal workflow looks like:
- Scan files
- Download necessary files
- Parse the heck out of them
- Modify documents
- Reupload documents with all that stuff.
- Wait
- Do so again
** Flowcharts
*** File Process function
#+DOWNLOADED: file:///home/rohan/Downloads/code2flow_7VJvnF.svg @ 2021-02-03 13:11:05
[[file:Criterion_B/2021-02-03_13-11-05_code2flow_7VJvnF.svg]]
*** Process of getting link metadata
#+DOWNLOADED: file:///home/rohan/Downloads/code2flow_BVudc9.svg @ 2020-09-16 12:34:06
[[file:Criterion_B/2020-09-16_12-34-06_code2flow_BVudc9.svg]]
*** Iterate over the lines in a file, replacing links with a format including the metadata
#+DOWNLOADED: file:///home/rohan/Downloads/code2flow_UwsW7j%20(1).svg @ 2020-09-16 12:33:41
[[file:Criterion_B/2020-09-16_12-33-41_code2flow_UwsW7j%20(1).svg]]
*** Extract document metadata

#+DOWNLOADED: file:///home/rohan/Downloads/code2flow_sPfF6L.svg @ 2021-02-02 19:35:54
[[file:Criterion_B/2021-02-02_19-35-54_code2flow_sPfF6L.svg]]

*** Batch Process: Wrapper function that calls all other subroutines in sequence
#+DOWNLOADED: file:///home/rohan/Downloads/code2flow_BaieTB.svg @ 2020-11-15 17:30:01
[[file:Criterion_B/2020-11-15_17-30-01_code2flow_BaieTB.svg]]

** Designs
*** UI: General Settings
#+DOWNLOADED: file:///home/rohan/Pictures/1609309565.png @ 2020-12-30 10:27:07
[[file:Criterion_B/2020-12-30_10-27-07_1609309565.png]]
(Created using Bootstrap Studio, a free mockup tool. A crude mockup of how the 'general settings' component of the settings view might look.)
*** UI: Custom Rules
#+DOWNLOADED: file:///home/rohan/Pictures/1612095523.png @ 2021-01-31 16:19:38
[[file:Criterion_B/2021-01-31_16-19-38_1612095523.png]]

*** Config options
- Run every {n} minutes
- Auto-format docs: y/n
- Root path
# NOTE: They fill in a path, which we convert to a drive folder_object. The program parses '/' as the top level and descends from there
- Authorise and de-authorise buttons: Authorise calls the 'webserverauth()' method, allowing the user to re-authorise the app
- Link to take you to the folder in Gdrive
- A section for custom rules

*** Config internal representation (JSON file)
#+BEGIN_SRC json
{"delay":5,
 "autoformat":true,
 "root":"/mun",
 "folder-link":"This will be generated based on folder-ids and the root path",
 "custom-rules":
    {"name": [{"regex":"[Pp]osition [Pp]aper","type":"position paper"}],
    "contains":[{"regex":"Urges","type":"resolution"}]}
}
#+END_SRC

*** Metadata format
#+BEGIN_SRC python
metadata = {
    "type": ("source", "notes", "position paper", "resolution"),
    "agenda": "string",
    "committee": "string",
    "country": "string",
    "filetype": ("[m]html", "pdf", "docx", "googledoc", "md", "org", "misc"),
}
#+END_SRC

*** Heuristics for defining document type
#+BEGIN_SRC python
if mime in ("HTML", "MHTML", "PDF"):
    return "source"

if mime in ("docx", "google docx", "md"):

    if document.matches("\w* https://\w*/ \w*"): # A link surrounded by words. Common in notes, not in papers
        return "notes"

    doctree=Tree(document) # # Trees based on paragraphs, lists, linebreaks, etc.
    lists=[(l, l.depth()) for l in document.lists] #Depth is how far it is nested
    if max(lists, key=lambda elem:elem[0])>=2: # Depth 0 means shallow. Searches for the highest depth in the document, i.e the most nested lists we have.
        return "resolution"
#+END_SRC

*** Clause data structure
An MUN clause is basically a statement, which can have an arbitrary number of subclauses, each of which can have an arbitrary number of sub-subclauses, etc.

Thus, the ideal data structure for representing an MUN resolution (a collection of clauses) is using a structure based on a tree. Each clause will have a root, which is the text of the clause as a string. It will also have children, which themselves are clauses with roots and children: The bottom-level, or end of a clause, is when all of it's children have no children of their own and the tree terminates.
# NOTE: For this, consider replacing with pseudocode
# TODO: Add flowcharts for some, in place (or alongside pseudocode)
#+BEGIN_SRC python
class Tree:
    def __init__(rootstring):
        self.root=rootstring
        self.children=[]

    def addChild(self, child):
        self.children.append(Tree(child))
        pass

    def getChild(self, n):
        return self.children[n]

    def getNestedChild(self,*args):
        if len(args)==1:
            return self.getChild(self, args[0])
        else:
            return self.getNestedChild(self,args[1:])
#+END_SRC

*** Sample directory structure
- /
  - MUN
    - Agenda: Combating digital terrorism
    - Agenda: Tourism after COVID-19
    - Position Papers
    - Resolutions
    - Notes
    - Resources
    - Recent
    - {All documents}

** Testing
*** COMMENT Preliminaries (setup)
- Create a throwaway Google account
- Copy my various MUN documents/notes from my main Drive to the new Drive
- Authorise my program to use this account

*** Unit tests
**** Drive retrieval/metadata manipulation functions (Success Criteria 2,7,9)
 Call the following code (It finds a file, reads the content, adds metadata, and reads that new metadata:
 #+BEGIN_SRC python
x=getFile('Position Paper')
y=addMetadata(x,{'type':'position paper'})
y.Upload()
print(getMetadata(y))
 #+END_SRC
It should run without error and print {type:position paper}

**** Link metadata functions (Success Criteria 6,12)
#+BEGIN_SRC  python
print(getLinkData("https://www.un.org/securitycouncil/content/resolutions-0"))
#+END_SRC
It should correctly retrieve the webpage title, and the source website.
**** Auto-formatting functions on a local document (Success Criteria 4,11)
- Create a local Word/Docx file with intentional formatting errors (based on tinkering with an old MUN document a friend of mine created).
- Pass it through the auto-formatter. Inspect the output- this must be done by eye.

**** Referencing/linking functions (Success Criteria 10)
#+BEGIN_SRC python
folder=createFolder('mun-unit-test')
folder.Upload()
paper=getFile('mun-paper')
link=createLink(paper,folder)
link.Upload()
#+END_SRC
On visiting the folder in the Drive web interface, there should be a folder mun-unit-test with a file mun-paper in it.
# Ran without error, but the file was not copied
**** Link replacer functions (Success Criteria 6,12)
#+BEGIN_SRC python
fname="/home/{user}/tmp/IOC_Extract.docx"
replaceLinks(fname)
#+END_SRC
This should replace all the links in the given file with a string that includes metadata, and write that new file to the file ~{fname}-links_replaced.docx~. Then inspect that file to ensure link replacement went properly.

*** Integration tests
**** Metadata tagging functions (Sucess Criteria 1,2,3,6,7,9,10)
Call the ~classifier()~ function on 3 different kinds of documents in Google Drive, inspect the output to make sure it aligns with my expectations

**** Document parsing/interpretation suite (Success Criteria 4,11)
- Create a Google doc with 3 top-level clauses, each with a certain number of sub- and sub-sub-clauses.
- Load that document.
- Call the parse function on the loaded document, and save the result into a variable
- Print the first full clause of the variable.
- Print the second subclause of the second clause, top-level only.

**** UI (Sucess Criteria 5, 13-17)
- Execute the file webform.py, and navigate to http://127.0.0.1:5000.
- The web UI should be a form with buttons and text fields, structured in line with the design.
- Write some values in the fields, and press 'Save Settings'.
- Check the file config.json: The file should reflect the typed values.
- Click the 'view folder' link. It should go to the proper folder.

*** COMMENT Performance/stress-testing
- Upload a large amount of MUN files (specifically, all of my notes and research for a particular conference) to a particular folder in Google Drive
- Point the program to that folder using the configuration.
- Run the program with the following prefix ~perf-record~. This profiles the memory, cpu, used by the program and writes it to the file perf.data
# Consider using  ~systemd-run --scope -p MemoryMax=300M CPUQuota=200%~
- Note the start time
- Continue using my computer to do whatever I want
- If the computer slows down due to the program running, this means it is insufficiently optimised.
- Note the time when the program exits
- Look at the values in perf.data. If the program takes up more than 250MB of RAM or more than 10% of CPU on average, it needs further optimisation.

* Criterion C
** UML
*** batchProcess() function: High-level overview of how the program works

#+DOWNLOADED: file:///home/rohan/Downloads/code2flow_QL3FIE.svg @ 2021-01-12 12:20:05
[[file:Criterion_C/2021-01-12_12-20-05_code2flow_QL3FIE.svg]]

*** getMainFolder() function: Given a file path, retrieve the Google Drive File resource at that path

#+DOWNLOADED: file:///home/rohan/Downloads/mainfolder.svg @ 2020-10-11 17:00:35
[[file:Criterion_C/2020-10-11_17-00-35_mainfolder.svg]]

*** Document Classification Heuristic (Slightly simplified for brevity)

#+DOWNLOADED: file:///home/rohan/Downloads/classify.svg @ 2020-10-11 17:00:28
[[file:Criterion_C/2020-10-11_17-00-28_classify.svg]]

*** Tree and Clause objects
#+DOWNLOADED: file:///home/rohan/d/cs/ia/tree.svg @ 2020-10-11 17:02:12
[[file:Criterion_C/2020-10-11_17-02-12_tree.svg]]

** Code Structure
I divided my code into 3 files: One which handled the interfacing with google drive, one which handled the manipulation of local Docx files, and one which handled the web GUI.
*** Webform Structure
#+DOWNLOADED: file:///home/rohan/Pictures/webform.png @ 2020-11-17 10:38:34
[[file:Criterion_C/2020-11-17_10-38-34_webform.png]]

*** Google Drive manipulation structure
#+DOWNLOADED: file:///home/rohan/Pictures/utils.png @ 2020-11-17 10:39:31
[[file:Criterion_C/2020-11-17_10-39-31_utils.png]]

** Complex code and explanation
*** Data structures: Hash tables
My program makes extensive use of dictionaries (key-value stores). The metadata added to documents is represented as a structured hashtable. This allows them to be serialised to plaintext more easily, making it easier to send the data to the Drive API.
#+BEGIN_SRC python
  def createFolder(name, parent_id, drive=mydrive):
      folder_metadata = {
          "title": name,
          # The mimetype defines this new file as a folder, so don't change this.
          "mimeType": "application/vnd.google-apps.folder",
          "parents": [{"kind": "drive#parentReference", "id": parent_id}],
      }
      return drive.CreateFile(folder_metadata)
#+END_SRC

I also use hashtables to store associations. I use a hashtable to associate MIME types with informal names, such as associating ~application/vnd.openxmlformats-officedocument.wordprocessingml.document~ with ~"word"~. This lets me refer to the informal name in my program - if the mimetype changes or I wish to add new ones, I need only tinker with the conversion table rather than rewrite any logic.

#+BEGIN_SRC python
  conversion_table = {
      "application/vnd.google-apps.document": "gdoc",
      "application/pdf": "pdf",
      "application/vnd.openxmlformats-officedocument.wordprocessingml.document": "word",
      "text/html": "html",
      "message/rfc822": "mhtml",
      "application/x-mimearchive": "mhtml",
  }
#+END_SRC

*** File/Data: JSON
Students have different workflows for how they manage documents, so the program must be configurable. I introduced options that modify the programs behaviour. For instance, the user decides where to store documents, and the program automatically finds that folder in Google Drive.

User data must be persistent, and so I store it as JSON, in a file named ~"config.json"~ (The structure of which is defined in criterion B). JSON provides a convenient way to store configuration keys/values.
#+BEGIN_SRC python
config = json.load("./config.json")
folderpath = config["root"]
if "folder-link" not in config:
    folderlink = getMainFolder(folderpath)["alternateLink"]
    config["folder-link"] = folderlink
    json.dump(config, "./config.json")
# Snippet reads the json file, gets the path of the folder, and converts it to a link to the relevant Google Drive folder.
# getMainFolder() is defined elsewhere in the code.
#+END_SRC

*** GUI: HTML
Although Python is system-agnostic, since people don't have python pre-installed on their systems it needs to be compiled for specific OS's.

Since compiling python with GUI libraries is difficult, I use an HTML+JS form as my GUI. My program runs as a webserver on the user's local computer, and serves an HTML page. When users save settings, the program parses the response, saving it to JSON. The users are presented with a familiar interface, and they don't need libraries to access it, making the program more usable.

To make the GUI palatable, I used the bootstrap framework, which provides configurable CSS:[fn:1]


#+DOWNLOADED: file:///home/rohan/Pictures/1603364009.png @ 2020-10-22 14:53:43
[[file:Criterion_C/2020-10-22_14-53-43_1603364009.png]]

*** Data structures: Trees
MUN Clauses can be arbitrarily nested- clauses have subclauses, which have sub-subclauses, and so on. Representing this requires a fundamentally recursive data structure. I chose a tree, since structured documents (like markdown files) are parsed as trees. My tree structure uses a list to represent its children (any node can have arbitrarily many children).[fn:2]

#+BEGIN_SRC python
class Tree:
    # Attributes: A list of children, all of whom are either trees or empty.
    def __init__(self, rootstring, parent=None):
        self.root = rootstring
        self.children = []
        self.parent = parent

    def __str__(self):
        return self.root

    def addChild(self, child):
        self.children.append(Tree(child, self))
#+END_SRC

*** Recursion on Trees
I defined an algorithm ~maxDepth~ that finds the height of a tree. This can determine the level of clause nesting in a resolution, and thus identify whether a document is a resolution or not. It's also vital for understanding the structure of a document when auto-formatting.

I designed an algorithm ~getNestedChild~, which identifies elements in a tree by their "coordinates". To get the first child of the first child of the root node, you would call ~getNestedChild(0,0)~. The algorithm recursively descends the tree, and with each level it descends it slices off the first argument (i.e coordinate), navigating the tree with minimal overhead.[fn:3]
#+BEGIN_SRC python
    def maxDepth(self):
        if self.children:
            depths = [i.maxDepth() for i in self.children]
            return max(depths) + 1
        else:
            return 0
        # Tree with only one node (no children) registers as depth 0.

    def getChild(self, n):
        return self.children[n]

    def getNestedChild(self, *args):
        if len(args) == 1:
            return self.getChild(args[0])
        else:
            return self.getChild(args[0]).getNestedChild(*args[1:])
#+END_SRC

*** Tree objects and inheritance
In addition to the basic Tree object, I defined a subclass ~Clause~. This inherits methods like ~__init__~ and ~maxdepth~ from ~Tree~, but includes new methods like ~fromDocArr~, allowing us to construct a specialised tree from a word document. It also includes methods like ~~format~~.
#+BEGIN_SRC python
class Clause(Tree):

    #    @staticmethod
    def fromDocArr(docArr):
        root = Tree("Document Start")
        toplevels = "Everything without a tab in front"
        indices = "That but indices"
        toplevels = [Tree(i) for i in toplevels]
        # Omitted for brevity

    def appendOrReplace(target, replacer):
        # Check if the last char is punctuation. If so, replace it with replacer. Otherwise, append replacer to target.
        last = target[-1]
        if last in "!&*-;:,.?":
            target[-1] = replacer
            return target
        else:
            return target + replacer

    def format(self):
        # Regardless of nesting level, we basically have a semicolon at the end of every sub* clause except the last one, which has a.
        # So for every clause, I'd suggest children[-1] have a fullstop added. For the rest, if they have children, append a ":", else append a ";"
        # If the last char is a punctuation mark, replace it, otherwise append.
        body = self.root
        if self.children:
            self.appendOrReplace(":")
        else:
            self.appendOrReplace(";")
#+END_SRC
*** Libraries
My solution interfaces with external libraries and APIs. For instance, it uses ~pydrive2~ to interface with Google Drive, such as to retrieve documents and manipulate metadata.

It also uses ~python-docx~ to parse word documents. Specifically, it uses ~docx2python~ to convert a document into a structured array based on its XML representation. Using optimized libraries like this improves performance, and means fewer bugs - I don't have to exhaustively study the Word document specification, which simplifies the code.

I also use elements from the standard library to handle JSON serialisation, file management, network requests, etc. Since the standard library is precompiled C, it's more performant than my own implementations.

#+BEGIN_SRC python
from pydrive2.auth import GoogleAuth
from pydrive2.drive import GoogleDrive
from urllib.parse import urlparse
from bs4 import BeautifulSoup
#+END_SRC

#+BEGIN_SRC python
import docx
from docx2txt import process as asTxt
from os import path
from docx2python import docx2python as asArr
from pprint import pprint
from re import findall
#+END_SRC

*** Quasi-functional programming: Optimising Network Calls
In testing the program, I discovered calls to ~Upload()~ and ~Download()~ from the Google Drive API were by far the most expensive components of my programming. I borrowed some ideas from functional programming - Instead of uploading the file with each function, the function accepts a DriveFile object (defined in the Pydrive2 library) and returns a modified version of it. Thus, I can chain multiple such functions together and simply upload the last returned object with all the changes made, which greatly increases the programs performance.

#+BEGIN_SRC python
# An example of quasi-functional code
def createFolder(name, parentId, drive=mydrive):
    """Creates and returns a drive folder within the path specified by parentId, and with the given name. If one exists already, return that instead

    :param name: The name of the folder
    :param parentId: The Id of the folder in which the new folder should be created
    :param drive: The GoogleDrive object representing a drive to modify
    :returns: An existing folder, if one is found, else a new one with the specified name and parent
    :rtype: DriveFile object

    """
    folderMeta = {
        "title": name,
        # The mimetype defines this new file as a folder, so don't change this.
        "mimeType": "application/vnd.google-apps.folder",
        "parents": [{"kind": "drive#parentReference", "id": parentId}],
    }
    x = getExistingFolder(name, parentId, drive)
    return x if x else drive.CreateFile(folderMeta)
# If a folder with that name already exists at that path, just return that instead of creating a new on# If a folder with that name already exists at that path, just return that instead of creating a new onee
#+END_SRC

*** Advanced Data Structures: Navigating nested arrays
To extract metadata from documents, I had to traverse an arbitrarily-nested array. To handle this neatly, I defined a recursive ~flatten~ function. Since it deals exclusively with lists and tuples, it uses the python construct ~yield~ instead of return. Thus, it returns individual elements, which automatically accumulate into an iterable.[fn:5].
#+BEGIN_SRC python
def flatten(iterable):  # WARNING: Does not work on dicts
    it = iter(iterable)
    for e in it:
        if isinstance(e, (list, tuple)):
            for f in flatten(e):
                yield f
        else:
            yield e
# Recursively expands everything until it stops being a list/tuple.
#+END_SRC

*** COMMENT List comprehensions and filtering
Python has a quasi-functional construct known as list comprehensions, which implement the equivalent of ~map~ and ~filter~ functions. I use these to manipulate arrays, calling functions on individual elements and/or filtering arrays. These allowed me to elegantly and readably construct new lists.
#+BEGIN_SRC python
clean = flatten(docArr)  # Each elem of clean is a line of text
lowered = [i.lower() for i in clean]
meta = [i for i in lowered if ":" in i or "-" in i]
agenda = [i for i in meta if "topic" in i]
committee = [i for i in meta if "committee" in i]
country = [i for i in meta if "country" in i]
# Using list comprehensions to find lines which may contain useful metadata about documents and save them to a list for further processing.
#+END_SRC
*** File manipulation
The ~python-docx~ library is unable to read or modify hyperlinks in a document. Thus, I interacted directly with Word files, which are ultimately just a collection of XML files. I worked with file structures to create an automated pipeline that extracts a word document as a zip file, replaces link text with a formatted string containing link metadata, and writes it back to the original without corrupting any data.
#+BEGIN_SRC python
def writeToDoc(folderPath):
    """Write a folder (the result of unzipping a word doc) to a word doc

    :param folderPath: Path of the unzipped word doc
    :returns: Path to the created docx file
    :rtype: Path

    """
    docPath = folderPath.resolve().parents[1] / (folderPath.name + ".docx")
    # pyMUN folder, then find the filename
    d = shutil.make_archive(docPath, "zip", folderPath)
    shutil.move(d, docPath)
    return docPath


def getDocumentFile(folderPath):
    """Given the path to an unzipped word doc, find actual document.xml file

    :param folderPath:Path to word doc (zip file)
    :returns: Path to the document.xml file contained within it
    :rtype: String (path)

    """
    return (
        f"{folderPath}word/document.xml"
        if str(folderPath)[-1] == "/"
        else f"{folderPath}/word/document.xml"
    )
#+END_SRC
*** Storing form responses using 2d arrays
The ~custom-rules~ section of the form includes a list of rules, each with the following structure: ~[searchtype, searchtext, doctype]~. For instance, a rule might have ~[fulltext, urges, position]~, indicating any document containing the word 'urges' should be classified as a position paper. I stored the rules in a ~nx3~ matrix, and used that to translate them into a JSON representation.

#+BEGIN_SRC python
rule_matrix = [
    request.form.getlist("type"),
    request.form.getlist("text"),
    request.form.getlist("doctype"),
] # Individual column of the form (type,text,doctype)
rule_count = len(rule_matrix[0])
rule_json = {"name": [], "contains": []}
for i in range(rule_count):
    formatted_rule = {"regex": rule_matrix[1][i], "type": rule_matrix[2][i]}
    rule_json[rule_matrix[0][i]].append(formatted_rule) # Appends to either "name" array or "contains" array, depending on the type of rule
#+END_SRC
*** Jinja Templates: Abstracting UI from logic
My UI is in HTML, using the Jinja2 templating engine. I used Flask and WTForms to define the relevant fields with attributes, and created a Jinja template which automatically loads this text when rendered. Thus, I was able to separate the interface from the design (of the form fields and description) and the logic[fn:7].
#+BEGIN_SRC html
<form action="" method="post" role="form">
    <div class="form-group">
        <p>{{ form.delay.label }}<br>
            {{ form.delay(class_="form-control") }}
        </p>
        <small class="form-text text-muted">{{ form.delay.description }}</small><br>
#+END_SRC
#+BEGIN_SRC python
class ConfigForm(FlaskForm):
    delay = TextField(
        "Delay:", description="Time between program updates/runs (in minutes)"
    )
# Partial sample only, for brevity
#+END_SRC


*Word Count: 990*
** Sources
*** Libraries
- Bootstrap, 2020. Bootstrap 4.5.3 [library] Available at: <https://github.com/twbs/bootstrap>

- Google API Team, 2020. Googleapis/Google-Api-Python-Client. [online] GitHub. Available at: <https://github.com/googleapis/google-api-python-client> [Accessed 10 October 2020].

- Gwak, J., 2020. Iterative/Pydrive2. [online] GitHub. Available at: <https://github.com/iterative/PyDrive2> [Accessed 10 October 2020].

- Hill, S. 2020. Docx2Python [library] Available at: <https://github.com/ShayHill/docx2python>

- Lipovsky, J. 2020. URLExtract 1.1 [library] Available at: <https://github.com/lipoja/URLExtract>

- Pallets, 2020. Flask 1.1.2. [library] Available at: <https://github.com/pallets/flask>

- Richardson, L. 2020. Beautiful Soup 4 [library] Available at: <https://www.crummy.com/software/BeautifulSoup/>

- Senetar, A. 2018. Send2Trash 1.5.0 [library] Available at: <https://github.com/arsenetar/send2trash>

- Shah, A. 2019. Python-Docx2Text 0.8 [library] Available at: <https://github.com/ankushshah89/python-docx2txt>

- WTForms, 2020. WTForms 2.3.3 [library] Available at: <https://github.com/wtforms/wtforms>

*** Official Documentation
- Canny, S., 2020. Python-Docx — Python-Docx 0.8.10 Documentation. [online] Python-docx.readthedocs.io. Available at: <https://python-docx.readthedocs.io/en/latest/index.html> [Accessed 10 October 2020].

- Canny, S., 2020. Working With Text — Python-Docx 0.8.10 Documentation. [online] Python-docx.readthedocs.io. Available at: <https://python-docx.readthedocs.io/en/latest/user/text.html> [Accessed 10 October 2020].

- Google Developers, 2020. Google Workspace And Drive MIME Types  |  Google Drive API. [online] Google Developers. Available at: <https://developers.google.com/drive/api/v3/mime-types> [Accessed 10 October 2020].

- Google Docs Developers, 2020. Python Quickstart  |  Google Docs API  |  Google Developers. [online] Google Developers. Available at: <https://developers.google.com/docs/api/quickstart/python> [Accessed 10 October 2020].

- Google Docs Developers, 2020. REST Resource: Documents  |  Google Docs API  |  Google Developers. [online] Google Developers. Available at: <https://developers.google.com/docs/api/reference/rest/v1/documents#Document> [Accessed 10 October 2020].

- Google Drive Developers, 2020. Files  |  Google Drive API  |  Google Developers. [online] Google Developers. Available at: <https://developers.google.com/drive/api/v3/reference/files> [Accessed 10 October 2020].

- Google Drive Developers, 2020. Files: Export  |  Google Drive API  |  Google Developers. [online] Google Developers. Available at: <https://developers.google.com/drive/api/v3/reference/files/export> [Accessed 10 October 2020].

- Google Drive Developers, 2020. Files: List  |  Google Drive API  |  Google Developers. [online] Google Developers. Available at: <https://developers.google.com/drive/api/v2/reference/files/list#python> [Accessed 10 October 2020].

- Google Drive Developers, 2020. Search For Files And Folders  |  Google Drive API  |  Google Developers. [online] Google Developers. Available at: <https://developers.google.com/drive/api/v2/search-files> [Accessed 10 October 2020].

- Gwak, J., Blevins, S. and Nabel, R., 2020. Quickstart — Pydrive 1.3.0 Documentation. [online] Gsuitedevs.github.io. Available at: <https://gsuitedevs.github.io/PyDrive/docs/build/html/quickstart.html> [Accessed 10 October 2020].

- Gwak, J., Blevins, S. and Nabel, R., 2020. Welcome To Pydrive’S Documentation! — Pydrive 1.3.0 Documentation. [online] Gsuitedevs.github.io. Available at: <https://gsuitedevs.github.io/PyDrive/docs/build/html/index.html> [Accessed 10 October 2020].

- Python Software Foundation, 2020. Urllib.Parse — Parse Urls Into Components — Python 3.9.0 Documentation. [online] Docs.python.org. Available at: <https://docs.python.org/3/library/urllib.parse.html> [Accessed 10 October 2020].

- Python Software Foundation, 2020. Zipfile — Work With ZIP Archives — Python 3.9.1 Documentation. [online] Docs.python.org. Available at: <https://docs.python.org/3/library/zipfile.html> [Accessed 8 December 2020].

- Pallets, n.d. Data Structures — Werkzeug Documentation (1.0.X). [online] Werkzeug.palletsprojects.com. Available at: <https://werkzeug.palletsprojects.com/en/1.0.x/datastructures/#werkzeug.datastructures.MultiDict> [Accessed 8 December 2020].

- Pallets, n.d. Template Designer Documentation — Jinja Documentation (2.11.X). [online] Jinja.palletsprojects.com. Available at: <https://jinja.palletsprojects.com/en/2.11.x/templates/> [Accessed 13 January 2021].

- Stratis, K., n.d. How To Use Generators And Yield In Python – Real Python. [online] Realpython.com. Available at: <https://realpython.com/introduction-to-python-generators/> [Accessed 13 January 2021].
*** Code snippets
- Paloor, J., 2017. Python Program To Read A Url And Extract Its Meta Keyword And Meta Description. [online] Gist. Available at: <https://gist.github.com/jineshpaloor/6478011> [Accessed 10 October 2020].
*** Other

- Altenkirch, T., 2020. Coding Trees In Python. [video] Available at: <https://www.youtube.com/watch?v=7tCNu4CnjVc> [Accessed 10 October 2020].

- Jablonski, J., 2020. Python 3'S F-Strings: An Improved String Formatting Syntax (Guide) – Real Python. [online] Realpython.com. Available at: <https://realpython.com/python-f-strings/> [Accessed 10 October 2020].

- KFC, 2020. Model UN Made Easy: How To Write A Resolution - Best Delegate Model United Nations. [online] Best Delegate Model United Nations. Available at: <https://bestdelegate.com/model-un-made-easy-how-to-write-a-resolution/> [Accessed 10 October 2020].

- Malik, U., 2020. Reading And Writing MS Word Files In Python Via Python-Docx Module. [online] Stack Abuse. Available at: <https://stackabuse.com/reading-and-writing-ms-word-files-in-python-via-python-docx-module/> [Accessed 10 October 2020].

- Mozilla, 2019. Common MIME Types. [online] MDN Web Docs. Available at: <https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/MIME_types/Common_types> [Accessed 10 October 2020].

- Mozilla, 2019. MIME Types (IANA Media Types). [online] MDN Web Docs. Available at: <https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/MIME_types> [Accessed 10 October 2020].

- Pythonspot, 2020. Python Tree Data Structure. [online] pythonspot. Available at: <https://pythonspot.com/python-tree/> [Accessed 10 October 2020].

* COMMENT Criterion D
** Script
(Intro)
Welcome to my Computer Science IA Criterion D video documentation. My product is a desktop application to help students manage their MUN research resources and documents in google drive, and my client is the supervisor of our school's MUN club.
First, I'll outline the code structure, and demonstrate what makes the design extensible. We can see that the code is broken into three files: ~gdrive_tools.py, docx_tools.py, and webform.py~.
~gdrive_tools~ includes utilities for interacting with google drive (and most of the main code), ~docx_tools~ includes functions for parsing and reading docx files (word documents), and ~webform~ includes a Flask object which defines the User Interface, and some utilities to help it interact with the other files.
Within each file, the code is broken down into separate functions, with some simple objects there as well.
Additionally, looking at ~gdrive_tools~, I've imported functions from other files, meaning that code can be shared within files easily.
Looking at ~docx_tools~, I've separated the builtin classifier and the custom classifier which works on custom rules built by the user.
Most of the individual functions are quite short, and the features come from composing them together. Thus, we can quite easily write new functions to process metadata in new ways, or additional checks and heuristics for parsing/classifying documents.
The UI is also broken into components. The main UI is here (show UI), but it includes a line to dynamically import this other template, based on the settings in the config file. So depending on how many custom rules the user has created, it can create arbitrarily many elements to show them. Thus, we can tinker with the representation of custom rules without affecting the broader UI - and similarly, we can introduce new configuration options without having to mess with the custom rules.

()
First, I'll introduce the UI. Running this auto-opens the UI. We can see that you can configure whatever you like. Creating a custom rule so that anything with the word 'position' in it becomes a position paper.
We can also re- and de-authorise the app easily. De-authorising simply destroys the file containing the client secret (the token needed for the program to access the API)(Demonstrate de- and re-auth).
Now, we save the settings and close the tab. In the other tab I have the folder with my MUN documents. We can see that this document doesn't have any metadata in the description section.

Now to run the main function. In the actual app, this will run in the background and the function will run regularly every 5 minutes. Here I just run it once for demonstration.
Once it's done, open up the relevant folder. If we look at the file with 'position' in the name, it's extracted the metadata correctly, showing the country/committee/topic. It's also been classified as a position paper, based on the custom rule.
Opening up the file itself, we see that the links in the bottom have been replaced with the title and source.
Going back, we can see that other files have been classified as well, based on the heuristics we defined.

The actual app would run periodically, and it would only download and analyse files with missing metadata each time.

** Extensibility
- Show that the code is neatly broken into files and functions
- Show how I import funcs between different files, so that code can be reused in different contexts.
- Show that the customClassifier is separated from the default classifier
- Demonstrate how we can apply new functions to the google doc just by adding it to the updatemetadata or batchProcess functions
- Show how we can define new custom rules as boolean functions.
- Show that the UI is broken up into bits. So we can easily add in components, or change the styling, without needing to overhaul everything.
- Overuse the phrase `separation of concerns'.
** Outline of plan
- Show custom rules settings
- Create custom rule
- Save
- Run ~main~ via ~, c c~
- Go to the main Gdrive thing.
- Open up a normal file, show it's been classified correctly
- Open up a file named deathray and show it's been classified correctly.
- Open a file to show the links have been formatted properly
- Consider showing an (already) formatted resolution.
- Show re- and de-auth functions
** Success Criteria
- NOTE: These are all shown already by the outline below, so just use that.
- Adds metadata
- OAuth
- Classify docs
- HTML GUI
- Links,  classifying some HTML files/PDFS as research sources
- Demonstrate link formatting

* Criterion E
** COMMENT Success Criteria
See OOWriter file
** Testing
(All tests not mentioned here were demonstrated in the video documentation)
*** Drive metadata manipulation
#+DOWNLOADED: file:///home/rohan/Pictures/1612519926.png @ 2021-02-05 14:45:57
[[file:Criterion_E/2021-02-05_14-45-57_1612519926.png]]

*** Link metadata
#+DOWNLOADED: file:///home/rohan/Pictures/1612520900.png @ 2021-02-05 14:46:07
[[file:Criterion_E/2021-02-05_14-46-07_1612520900.png]]

*** COMMENT Referencing/linking functions
*** Link replacement/reformatting
Screenshot of a link correctly formatted (within a citation) in a Google Doc:
#+DOWNLOADED: file:///home/rohan/Pictures/1612518679.png @ 2021-02-13 15:50:19
[[file:Criterion_E/2021-02-13_15-50-19_1612518679.png]]

** Client Feedback
The client generally approved of the app's features, and the way it handles things unobtrusively in the background.
However, they noted that the app needs more ways of /using/ the information it extracts/processes. For instance, they suggested that I introduce pop-ups and toolbars in the Drive UI that allowed users to see this information up-front (rather than hunting for it in the description)
They also suggested that the program's usability (for users who are less tech-savvy) is lacking, since there's no external documentation[fn:4], and there were no builtin examples of custom rules.

# # - The UI should be more responsive.
# - Would help if the app could sort files into folders
# - Sorting by conference would be helpful
# - Basically, there need to be better ways of /using/ the information this tool extracts, such as enhancements to the Google Drive UI.
# - External documentation would make this product more usable (I created a README in response to this suggestion)
# - The program should come with some built-in custom rules/overrides (for instance, if the document title contains 'Notes' it should be classified as such)
** Potential Improvements
*** Better heuristics based on user feedback
Since the only samples of MUN documents I had were my own (and those of some of my friends), some of the heuristics I use reflect my own idiosyncracies, or on conventions which might not be universal. With wider usage, I'll be able to determine these failings and correct for them. If there are custom classifications that a lot of users implement, I might include those as defaults within the main program.
*** COMMENT Reliable intelligent auto-formatting

*** Better rewriting/modifying documents
Modifying documents requires tinkering with a word document, which has an extremely complicated (and honestly quite opaque) specification, and its difficult to do so while preserving structure and formatting. More reliable ways to rewrite documents would make the auto-formatting feature more reliable. If any libraries exist for this they could be used, or we could implement various useful functions (such as modifying formatting, etc.) by modifying the XML.

*** Associate files with specific conferences, and sort them accordingly.
Currently, files can be associated with committees and topics. However, they can't be associated with specific dates and conferences. Doing so would allow users to 'archive' past documents and focus only on present conferences. It would also give users more
*** COMMENT Auto-open UI

*** Performance Improvements
As it stands, the program takes quite a long time to run, since it needs to download and process a lot of documents. There are a variety of changes which would likely improve performance. Caching document metadata, etc. might improve performance for frequently-changed documents, albeit at the cost of more memory/disk space.

For Google Docs, it's possible to analyse the document without downloading the entire thing, using the Google Docs API. I should introduce functionality which can accomplish that. It would mean that only Word documents would need to be fully downloaded, thus improving the program's performance.

*** Rewrite based on official specs
The current document parsing functions rely on XML parsing and on existing libraries. It is likely that a program which took into account the existing spec for docx files would be able to modify them while preserving structure and formatting, such as using the spec to identify which elements should be preserved and which should be manipulated.

However, since Microsoft Word is proprietary, it's unknown how much they adhere to these open specifications (especially since there's known incompatibility between open tools (LibreOffice Writer) and MS Word.

*** Automatically create shortcuts within the requisite folders
Google Drive no longer allows files to exist in multiple folders. Instead, they have introduced a shortcut mechanism where we can create multiple links to files within folders. Although this can be done using google's REST API (i.e. commands can be called using formatted https requests) it doesn't expose that functionality through pydrive. Introducing this functionality and integrating it with my code would be extremely helpful.
** COMMENT Extensibility (Technical)
I've used separation of concerns to decouple the UI presentation from the actual parsing of the settings. This means that UI improvements can be made with minimal hassle.
Similarly, the 'customisable' elements, such as the custom rules for classifiers, are separated from the program's own heuristic classifications and encapsulated within their own functions. Thus, it would be easy to introduce additional rules without modifying the core logic of the program, and to introduce more specific filtering mechanisms.

* COMMENT Planning for the MUN product
Today:
- Comprehensive spec
- Ms. Rizwana
- Draft crit A.

Reqs
Filesearch
Data structure manip
Polymorph
# Recursion
OOP stuff
= Libraries
Multi-dimensional arrays
= Complex data structs

** Ideas
[Digitile is a similar tool]
*** Web
- GDocs, etc. plugin


*** Python
- Gdocs tool. In essence, it has full access to a folder. Within that folder, there are a bunch of MUN files

** Data struct thinking
-
-
** Kinds of documents
-
* COMMENT Re-imagining the document classifier
** Classifier
*** Heuristics
- DONE-ish List indentation
- DONE Metadata presence? That's actually an interesting one, which I haven't considered before. If it has country, it's a position paper.
- Para structure
- DONE Links
- DONE List density (how much of the document is list)
- More heuristics for identifying position papers. Draw the flowchart to make sure the ifs and fors are nested properly.
**** Position paper
- Short
- Not many paragraphs
- Metadata DONE
- No links
**** Plan
The issue is reliably distinguishing between position papers and notes. So we should restructure the classifier function. There are two ways we can go: Simple and sophisticated
***** Simple DONE
- First, run a bunch of tests (list-based) to determine if it is or isn't a resolution. If it is, exit and return. We have a decent battery of tests so be a bit certain here
- If not, run tests such as links, para structure, metadata, to check if it's position or notes. This is iffy, so don't be afraid to call it 'unclassified' if necessary.
***** Complex
- Break the document into a tree structure, and do all this stuff to the tree. This is just a nice-to-have, so don't implement it until everything else is done.

**** Para structure testing
What are our options here? If it's >2 pages (How to check this) return notes
If it's less than 2 pages, we can't consider paragraph length, but we can consider number of paragraphs.
Maybe section count helps, but doubt it. So just use wordcounts, I guess. NOTE: Roughly 600 words/page. So that means <(900-1000) is our check.

So now how do we go about this?
We have the number of paras, and each of their wordcounts.
From here we can do simple stats:  max,min, mean, etc.
How can we use these? I'm not optimistic that we can, honestly.

** Metadata extractor
Question: Should we extract metadata after classification, or before? After might be better, since then we'll know what meta we can expect to look for. But we'll also need to take into account blackbox leakages from the classifier.
So we should do it after, but include some checks to make sure we aren't looking for something that isn't there.
For now, we have an ok hacky solution.
Getting note metadata reliably: No idea. Basically, we can give them null metadata, or we can search for existing metadata(existing agenda etc which we've found from parsing papers and resolutions). This last one would be messy, and require us to create a messy text file. So every time we parse metadata, we also write it to a text file. Not in the spec, so don't do it for now. So this isn't going to be implemented for now"""

** Treemaker

** DONE Autoformat
Don't put too much work into this - make it perpetually beta, and warn people not to use it (Add that warning as placeholder (in red, naturally), into the main UI)
* COMMENT Custom rules
** DONE UI
Define a 'component' of sorts (a horizontal form) that represents a customRule. When webform is initialised, it should read the custom rules and create components for each of them. Wrap all the components in a div or whatever. After the div, have a + button that adds a form element to the div using JS. This will be messy, and require duplication between JS and Py.
*** DONE
- Define component as JINJA template and/or JS var
- Add button that calls the 'newRule' method
- Define newRule in js.
- Define autoload func in python (to automatically read the rules)
- Define the py methods for writing these from the existing file: Add it to the conf_dict and prepopulate methods
- That's basically it.
 Oh god, we'll need to work with javascript or some kind of dynamic HTML.
** DONE Implementation
Basically, they give us three values: (Contains/name),(string),(classification).
We should call this from the updateMetadata func. We first check the namerules, then the containRules, and if none of those work we use magicParse. So it accepts a result obtained by downloadHelper, which has the title, localpath, etc.
So we pass the file object directly. We try it against the namerules, or
* COMMENT Notes
# - Time complexity/elegance
# - Separation accomplished through templates
# - Abstraction accomplished
# - Global variables: I only require one.
# - Questions: How many flowcharts for each criterion?
* COMMENT Feedback <2020-12-08 Tue>
- No names in final document (Format)
- Add TOC of sorts of complex code techniques. (Format)
- Defend why I used techniques: Too many buzzwords as it stands. Focus on justification/valuing
- Make it clear.
# - Go through and remove the unnecessary words.
- Remove the jokes
- Add in-text citations where apt, for things like trees and APIs.
# - Consider briefly annotating some entries with things like <library>, <documentation>, <theoretical reference>, etc. (Think about how to do this)
# - Consider doing that via formatting/colours
# - Add a blanket disclaimer to sources
* COMMENT TODO
- Ask Ms. Almas about personal information in the video
# - Ask her if I should include results from unit tests, etc. in criterion D/E
- Ms. Rizwana: Feedback via text/email
- Email thread appendix with Ms. Rizwana for crit A, outlining solutions and problems - Crit A: At least 3 pieces of evidence of consultation with client
- Good to keep a few failed criteria.
# - For test results: I should have them in criterion E as screenshots, but including some in the video is also good form
# - Flesh out crit D,E record of tasks
- GANTT
# - Structure diagram: Firstly a user story/workflow, and then possibly a listing of functions
- Consider justifying design and data structures briefly
# - Flowcharts: About 5-6. So add more
# - It seems UML should be in crit B
# - Flowcharts: B should have overview, and most of the charts
# - C should have charts for specific fiddly bits.
- Consider adding focus on client/objective in crit C
- Add crit C appendix, acknowledging libraries used
- In Crit D, include evidence of error handling and the like.
- In crit D video, add extensibility discussion: Discussion of layers for heuristics, and how multiple heuristics can be composed (such as the custom/builtin heuristics) to create sophisticated filters/analyses.
* COMMENT TODO <2021-02-13 Sat>
- Crit D: Add extensibility/layer discussion, and heuristic composition
- Mention client/objective in crit C (optional)
- Appendices
- GANTT

# - Make sure each criterion is covered by the test plan.
* COMMENT Consulting
- Compose message to Ms. Rizwana about this.
- Send her brief outline of designs
- Ask her what she thinks about it

* Footnotes

[fn:4] Based on this feedback, I created a README file distributed with the code.

[fn:7] Pallets, n.d. Template Designer Documentation — Jinja Documentation (2.11.X). [online] Jinja.palletsprojects.com. Available at: <https://jinja.palletsprojects.com/en/2.11.x/templates/> [Accessed 13 January 2021].


# [fn:6] Cite word-doc/xml related stuff here

[fn:5] Stratis, K., n.d. How To Use Generators And Yield In Python – Real Python. [online] Realpython.com. Available at: <https://realpython.com/introduction-to-python-generators/> [Accessed 13 January 2021].

# [fn:4] I can cite everything here

[fn:3] Pythonspot, 2020. Python Tree Data Structure. [online] pythonspot. Available at: <https://pythonspot.com/python-tree/> [Accessed 10 October 2020].

[fn:2] Altenkirch, T., 2020. Coding Trees In Python. [video] Available at: <https://www.youtube.com/watch?v=7tCNu4CnjVc> [Accessed 10 October 2020].

[fn:1] Bootstrap, 2020. Bootstrap 4.5.3 [library] Available at: <https://github.com/twbs/bootstrap>
* COMMENT Appendices
** Crit A
*** Initial Conversation
**** Problems Faced
-
*** Discussion of Problems, Finalising Solution
- Students: Sorting and keeping track of different documents (in a way more sophisticated than normal file management, and which is cognizant of existing MUN stuff)
- Formatting documents and keeping track of conventions
- Bibliography management (although there are existing tools for this, just under-utilised)
- Solution: Google drive `add-on' that can automatically identify documents, and format them in a way that respects conventions.
*** Outlining Requirements
- Usability
- Google Drive integration, since that's something commonly used
- Sorting
- Managing research resources/references, either within documents or externally
- Automated and unobtrusive, as far as possible
- Configurable, and adaptable to different styles and workflows
** COMMENT Crit B
** Crit C
*** Libraries
** Crit E
* COMMENT Submission
Use forms.zip structure
# HTML cover page

Folder:
Subfolder docs (including video)
Subfolder product
